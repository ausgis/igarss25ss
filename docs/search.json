[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IEEE IGARSS 2025 Summer School",
    "section": "",
    "text": "Preface\n\n\n\n\n\nThe conference website link: https://www.2025.ieeeigarss.org/.\nTopic:Tools for remote sensing and geospatial intelligence analysis: An example of climate impact on bushfire.\n\n\n\n\n\n\nNote\n\n\n\nIn each section, we will include Tools, Aim, Description of steps, and Code.\nPlease ensure that RStudio is installed on your computer and that you have signed up for a Google Earth Engine account. Below are the instructions for installing R and RStudio, as well as signing up for Google Earth Engine. Kindly follow the steps provided in the links:\n\nGuide for Installing R and RStudio: https://rstudio-education.github.io/hopr/starting.html\nGuide for Signing Up for Google Earth Engine: https://courses.spatialthoughts.com/gee-sign-up.html\n\nTo set up and open the igarss25ss R project locally, follow these steps:\n\nDownload the project archive Download the zipped repository from GitHub: https://github.com/ausgis/igarss25ss/archive/refs/heads/main.zip\nExtract the contents Unzip the downloaded file to a location of your choice. This will create a folder named: igarss25ss-main/\nOpen the R project Launch RStudio and open the file: igarss25ss-main/igarss25ss.Rproj This will load the project workspace and settings automatically.\n\nYou’re now ready to explore or work on the igarss25ss project in RStudio.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "sec1.html",
    "href": "sec1.html",
    "title": "\n1  Remote sensing data collection\n",
    "section": "",
    "text": "1.1 Define study area\nFigure 1.1: The location of study area, West Daly, in Australia",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Remote sensing data collection</span>"
    ]
  },
  {
    "objectID": "sec1.html#collecting-bushfire-data",
    "href": "sec1.html#collecting-bushfire-data",
    "title": "\n1  Remote sensing data collection\n",
    "section": "\n1.2 Collecting bushfire data",
    "text": "1.2 Collecting bushfire data\n\n\n\n\n\n\nAim\n\n\n\nThis code is designed to compute and export the annual burned area from the MODIS MCD64A1 dataset using Google Earth Engine (GEE).\n\n\n\n\n\n\n\n\nDescription of steps\n\n\n\n\nLoad the MODIS MCD64A1 burned area dataset from GEE.\nDefine a function to clip and export burned area data by year.\nSet a time range (January 1st to December 31st of the given year).\nFilter the dataset for the selected year and extract the burned area information.\nApply an aggregation method (e.g., mean) to summarize burned area data.\nClip the data to the Region of Interest (ROI).\nExport the processed burned area data to Google Drive as a GeoTIFF.\nLoop through the desired years (2000-2024) and execute the function.\n\n\n\n// Load the MODIS MCD64A1 dataset\nvar dataset = ee.ImageCollection(\"MODIS/061/MCD64A1\");\n\n// Define a function to clip the dataset and export it by year\nfunction exportYearlyBurnedArea(year) {\n  // Create a date range for the specific year\n  var startDate = ee.Date.fromYMD(year, 1, 1);\n  var endDate = startDate.advance(1, 'year');\n\n  // Filter the dataset for the specific year and clip to the ROI\n  var yearlyBurnedArea = dataset.filterDate(startDate, endDate)\n                                .select('BurnDate')\n                                .mean()  // Or use another appropriate aggregation method\n                                .clip(roi.geometry().bounds());\n\n  // Export the processed data\n  Export.image.toDrive({\n    image: yearlyBurnedArea,\n    description: 'BurnedArea_' + year,\n    scale: 500,  // Adjust resolution as needed\n    region: roi,\n    fileFormat: 'GeoTIFF'\n  });\n}\n\n// Loop through and export data for the years 2000 to 2024\nfor (var year = 2000; year &lt;= 2024; year++) {\n  exportYearlyBurnedArea(year);\n}\nThe GEE code link: https://code.earthengine.google.com/d82182549c638d61a9e2ddee4e65b466 .",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Remote sensing data collection</span>"
    ]
  },
  {
    "objectID": "sec1.html#collecting-climate-data",
    "href": "sec1.html#collecting-climate-data",
    "title": "\n1  Remote sensing data collection\n",
    "section": "\n1.3 Collecting climate data",
    "text": "1.3 Collecting climate data\n\nTemperature\n\n\n\n\n\n\n\nAim\n\n\n\nThis code is designed to compute and export the annual mean temperature from the ERA5-Land Hourly Temperature dataset using GEE.\n\n\n\n\n\n\n\n\nDescription of steps\n\n\n\n\nLoad ERA5 hourly temperature data from Google Earth Engine.\nDefine a function to compute the annual mean temperature.\nSet a time range (January 1st to December 31st of the given year).\nFilter the dataset for the given year and compute the mean temperature.\nConvert temperature from Kelvin to Celsius.\nClip the data to the ROI.\nExport the processed temperature data to Google Drive as a GeoTIFF.\nLoop through the desired years and execute the function.\n\n\n\n// Load the ERA5 daily temperature dataset\nvar dataset = ee.ImageCollection(\"ECMWF/ERA5_LAND/HOURLY\");\n\n// Define a function to calculate and export the annual mean temperature\nfunction exportYearlyTemperature(year) {\n  // Create the date range\n  var startDate = ee.Date.fromYMD(year, 1, 1);\n  var endDate = startDate.advance(1, 'year');\n\n  // Filter the dataset and compute the annual mean temperature (unit: K)\n  var yearlyTemperature = dataset.filterDate(startDate, endDate)\n                                 .select('temperature_2m')\n                                 .mean()  // Compute annual mean temperature\n                                 .subtract(273.15)  // Convert to Celsius\n                                 .clip(roi.geometry().bounds());\n\n  // Export the result to Google Drive\n  Export.image.toDrive({\n    image: yearlyTemperature,\n    description: 'Tem' + year,\n    scale: 5000,  // ERA5 resolution, recommended 5km (5000m)\n    region: roi,\n    fileFormat: 'GeoTIFF'\n  });\n}\n\n// Loop to calculate the annual mean temperature for the years 2000-2024\nfor (var year = 2000; year &lt;= 2024; year++) {\n  exportYearlyTemperature(year);\n}\nThe GEE code link: https://code.earthengine.google.com/7f49ceb9af5b14a83ca3b547d09ea433 .\n\nPrecipitation\n\n\n\n\n\n\n\nAim\n\n\n\nThis code is designed to compute and export the annual cumulative precipitation from the CHIRPS 5-day interval precipitation dataset using GEE.\n\n\n\n\n\n\n\n\nDescription of steps\n\n\n\n\nLoad CHIRPS 5-day interval precipitation data from Google Earth Engine.\n\nDefine a function to compute the annual cumulative precipitation.\n\nSet a time range (January 1st to December 31st of the given year).\n\nFilter the dataset for the given year and compute the total precipitation.\n\nClip the data** to the ROI.\n\nExport the processed precipitation data to Google Drive as a GeoTIFF.\n\nLoop through the desired years (2000-2024) and execute the function.\n\n\n\n// Load the CHIRPS dataset (5-day interval precipitation)\nvar dataset = ee.ImageCollection(\"UCSB-CHG/CHIRPS/PENTAD\");\n\n// Define a function to calculate and export the annual cumulative precipitation\nfunction exportYearlyPrecipitation(year) {\n  // Create the date range\n  var startDate = ee.Date.fromYMD(year, 1, 1);\n  var endDate = startDate.advance(1, 'year');\n\n  // Filter the dataset and compute the total precipitation for the year\n  var yearlyPrecipitation = dataset.filterDate(startDate, endDate)\n                                   .select('precipitation')\n                                   .sum()  // Compute annual total precipitation\n                                   .clip(roi.geometry().bounds());\n\n  // Export the result to Google Drive\n  Export.image.toDrive({\n    image: yearlyPrecipitation,\n    description: 'Pre' + year,\n    scale: 5000,  // CHIRPS resolution (~5.5 km), adjustable\n    region: roi,\n    fileFormat: 'GeoTIFF'\n  });\n}\n\n// Loop to compute annual cumulative precipitation for the years 2000-2024\nfor (var year = 2000; year &lt;= 2024; year++) {\n  exportYearlyPrecipitation(year);\n}\nThe GEE code link: https://code.earthengine.google.com/8e0573849ffa323cbbcd6bbf74695bed .",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Remote sensing data collection</span>"
    ]
  },
  {
    "objectID": "sec2.html",
    "href": "sec2.html",
    "title": "\n2  Temporal analysis for remote sensing data\n",
    "section": "",
    "text": "2.1 Temporal trend analysis for bushfire\nCodefs::dir_ls('./data/1. Data collection/BurnedArea',regexp = \".tif$\") |&gt; \n  terra::rast() -&gt; ba\nnames(ba) = paste0(\"BA\", 2000:2024)\n\nfs::dir_ls('./data/1. Data collection/Pre/',regexp = \".tif$\") |&gt; \n  terra::rast() -&gt; pre\nnames(pre) = paste0(\"Pre\", 2000:2024)\n\nfs::dir_ls('./data/1. Data collection/Tem/',regexp = \".tif$\") |&gt; \n  terra::rast() -&gt; tem\nnames(tem) = paste0(\"Tem\", 2000:2024)\n\nba |&gt; \n  terra::resample(tem,method = \"sum\",threads = TRUE) -&gt; ba\n\npre |&gt; \n  terra::resample(tem,method = \"average\",threads = TRUE) -&gt; pre\n\ngrid = c(ba,pre,tem)\n\nlm_fun = \\(x) {\n  if (all(is.na(x))) return(rep(NA, 3))\n  year = 2000:2024\n  fit = stats::lm(x ~ year,na.action = na.omit)\n  r2 &lt;- summary(fit)$r.squared\n  return(c(intercept=coef(fit)[1], slope=coef(fit)[2], r2=r2))\n}\n\nba_lm = terra::app(grid[[paste0(\"BA\", 2000:2024)]], \n                                 fun = lm_fun, cores=8)\nnames(ba_lm) = c(\"intercept\", \"slope\", \"r2\")\n\noptions(terra.pal = grDevices::terrain.colors(100,rev = T))\nterra::plot(ba_lm)\n# terra::writeRaster(ba_lm,'./data/2. Temporal analysis/lm.tif',overwrite = TRUE)\n\n\n\n\n\n\nFigure 2.1: Maps of the linear trend bettwen bushfire area and time",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Temporal analysis for remote sensing data</span>"
    ]
  },
  {
    "objectID": "sec2.html#temporal-correlation-analysis-between-bushfire-and-climate",
    "href": "sec2.html#temporal-correlation-analysis-between-bushfire-and-climate",
    "title": "\n2  Temporal analysis for remote sensing data\n",
    "section": "\n2.2 Temporal correlation analysis between bushfire and climate",
    "text": "2.2 Temporal correlation analysis between bushfire and climate\n\n\n\n\n\n\nAim\n\n\n\nThis code is designed to compute the Spearman correlation coefficients and p-values between burned area and precipitation/temperature for each grid cell over the years 2000-2024, and save the results as a new shapefile.\n\n\n\n\n\n\n\n\nDescription of steps\n\n\n\n\nLoad necessary libraries (terra, fs, and optionally dplyr for data manipulation).\nRead the raster files containing burned area, precipitation, and temperature data using terra::rast() and fs::dir_ls().\nAssign layer names to match the temporal sequence for each variable:\nBurned area (BA2000 to BA2024)\nPrecipitation (Pre2000 to Pre2024)\nTemperature (Tem2000 to Tem2024)\nCompute the Spearman correlation for each grid cell using terra::app():\nBurned area vs. Precipitation (cor_BA_Pre)\nBurned area vs. Temperature (cor_BA_Tem)\nAlso calculate the correlation p-values for statistical significance:\n\n\np_BA_Pre, p_BA_Tem, and p_Pre_Tem\n\n\n\nThe function returns six layers: three correlation coefficients and three corresponding p-values.\nVisualize the correlation results using terra::plot() or save the output raster with terra::writeRaster() for further analysis.\n\n\n\n\nCodecor_spearman_fun = \\(x) {\n  n = 25 \n  \n  y_ba  = x[1:n]\n  y_pre = x[(n+1):(2*n)]\n  y_tem = x[(2*n+1):(3*n)]\n  \n  if (all(is.na(y_ba)) || all(is.na(y_pre)) || all(is.na(y_tem))) {\n    return(rep(NA, 6))\n  }\n  \n  df = data.frame(BA = y_ba, Pre = y_pre, Tem = y_tem)\n  df = na.omit(df)\n  if (nrow(df) &lt; 3) return(rep(NA, 6))\n  \n  cor1 = suppressWarnings(cor.test(df$BA, df$Pre, method = \"spearman\",\n                                   use = \"complete.obs\", exact = FALSE))\n  cor2 = suppressWarnings(cor.test(df$BA, df$Tem, method = \"spearman\",\n                                   use = \"complete.obs\", exact = FALSE))\n  cor3 = suppressWarnings(cor.test(df$Pre, df$Tem, method = \"spearman\",\n                                   use = \"complete.obs\", exact = FALSE))\n  \n  return(c(cor_BA_Pre  = cor1$estimate,\n           cor_BA_Tem  = cor2$estimate,\n           cor_Pre_Tem = cor3$estimate,\n           p_BA_Pre    = cor1$p.value,\n           p_BA_Tem    = cor2$p.value,\n           p_Pre_Tem   = cor3$p.value))\n}\n\ncor_result = terra::app(grid, fun = cor_spearman_fun, cores = 8)\nnames(cor_result) = c(\"cor_BA_Pre\", \"cor_BA_Tem\", \"cor_Pre_Tem\",\n                       \"p_BA_Pre\", \"p_BA_Tem\", \"p_Pre_Tem\")\n\noptions(terra.pal = grDevices::terrain.colors(100,rev = T))\nterra::plot(cor_result)\n# terra::writeRaster(cor_result,'./data/2. Temporal analysis/cor.tif',overwrite = TRUE)\n\n\n\n\n\n\nFigure 2.2: Maps of the correlation between bushfire area and temperature/precipitation",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Temporal analysis for remote sensing data</span>"
    ]
  },
  {
    "objectID": "sec3.html",
    "href": "sec3.html",
    "title": "\n3  Spatial analysis for remote sensing data\n",
    "section": "",
    "text": "3.1 Spatial hotspot identification\nWe demonstrate a spatial analysis workflow using the 2024 climate and bushfire data as an example.\nWe will perform spatial hot spot and cold spot analysis using the rgeoda package and conduct spatial stratified heterogeneity analysis using the GD package.\nYou can install the required packages using the following commands in the R console:\nNow we read the data to R and perform some basic data exploration：\nSince the row and column numbers of the three rasters are not aligned, we first convert the non-NA cells of the temperature raster into a spatial polygon format. Then, we perform zonal statistics on temperature and wildfire data, and finally, remove all NA values corresponding to the three variables.\nsave the data to a shapefile:\nCodelibrary(sf)\nlibrary(rgeoda)\nlibrary(ggplot2)\n\nburnedarea = read_sf('./data/3. Spatial analysis/burnedarea_2024.shp')\nqueen_w = queen_weights(burnedarea)\nlisa = local_gstar(queen_w,  burnedarea[\"burnedarea\"])\ncats = lisa_clusters(lisa,cutoff = 0.05)\nburnedarea$hcp = factor(lisa_labels(lisa)[cats + 1],level = lisa_labels(lisa))\n\np_color = lisa_colors(lisa)\nnames(p_color) = lisa_labels(lisa)\np_label = lisa_labels(lisa)[sort(unique(cats + 1))]\nggplot(burnedarea) +\n  geom_sf(aes(fill = hcp)) +\n  scale_fill_manual(\n    values = p_color, \n    labels = p_label) +\n  theme_minimal() +\n  labs(fill = \"Cluster Type\")\n\n\n\n\n\n\nFigure 3.3: Bushfire burned area spatial hotspot analysis",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Spatial analysis for remote sensing data</span>"
    ]
  },
  {
    "objectID": "sec3.html#geographical-detector-for-spatial-heterogeneity-and-factor-analysis",
    "href": "sec3.html#geographical-detector-for-spatial-heterogeneity-and-factor-analysis",
    "title": "\n3  Spatial analysis for remote sensing data\n",
    "section": "\n3.2 Geographical detector for spatial heterogeneity and factor analysis",
    "text": "3.2 Geographical detector for spatial heterogeneity and factor analysis\n\n\n\n\n\n\nAim\n\n\n\nThis step is designed to identify the climatic driving factors of bushfire burned area. We will use the GD package to analyze the power of determinant of climatic drivers on bushfire burned area based on the optimal parameter geographical detector model.\n\n\n\n\n\n\n\n\nDescription of steps\n\n\n\n\nLoad necessary libraries (sf for spatial data and gdverse for geographical detector analysis).\nRead the burned area and climate data.\nRun the OPGD model.\n\n\n\n\nCodelibrary(sf)\nlibrary(GD)\n\nburnedarea = read_sf('./data/3. Spatial analysis/burnedarea_2024.shp')\nopgd.m = gdm(burnedarea~tem+pre, \n             continuous_variable = c(\"tem\", \"pre\"),\n             data = sf::st_drop_geometry(burnedarea),\n             discmethod = c(\"equal\",\"natural\",\"quantile\"), \n             discitv = 3:15)\nopgd.m\n# Explanatory variables include 2 continuous variables.\n# \n# optimal discretization result of tem\n# method             :  quantile\n# number of intervals:  13\n# intervals:\n#  26.7 26.8 27 27.2 27.3 27.5 27.7 27.7 27.7 27.8 27.9 28 28 28.2\n# numbers of data within intervals:\n#  52 47 52 47 53 47 50 49 50 50 48 50 49\n# \n# optimal discretization result of pre\n# method             :  natural\n# number of intervals:  14\n# intervals:\n#  1589 1650 1712 1736 1758 1787 1816 1844 1870 1896 1924 1949 1977 2011 2067\n# numbers of data within intervals:\n#  3 16 71 40 40 44 50 76 68 62 57 52 43 22\n# \n# Geographical detectors results:\n# \n# Factor detector:\n#   variable     qv      sig\n# 1      tem 0.1301 1.79e-10\n# 2      pre 0.0733 2.86e-05\n# \n# Risk detector:\n# tem\n#              itv meanrisk\n# 1   [26.69,26.8]     3730\n# 2   (26.8,27.02]     4871\n# 3   (27.02,27.2]     5984\n# 4   (27.2,27.33]     5647\n# 5  (27.33,27.51]     5514\n# 6  (27.51,27.66]     9252\n# 7  (27.66,27.69]     8948\n# 8  (27.69,27.74]     6647\n# 9  (27.74,27.83]     9489\n# 10 (27.83,27.91]     7340\n# 11 (27.91,27.96]     5083\n# 12 (27.96,28.02]     7738\n# 13 (28.02,28.16]     7136\n# \n# pre\n#                    itv meanrisk\n# 1  [1.59e+03,1.65e+03]     3435\n# 2  (1.65e+03,1.71e+03]     5166\n# 3  (1.71e+03,1.74e+03]     4348\n# 4  (1.74e+03,1.76e+03]     4829\n# 5  (1.76e+03,1.79e+03]     7293\n# 6  (1.79e+03,1.82e+03]     5739\n# 7  (1.82e+03,1.84e+03]     6155\n# 8  (1.84e+03,1.87e+03]     7578\n# 9   (1.87e+03,1.9e+03]     7887\n# 10  (1.9e+03,1.92e+03]     7212\n# 11 (1.92e+03,1.95e+03]     7933\n# 12 (1.95e+03,1.98e+03]     8390\n# 13 (1.98e+03,2.01e+03]     6340\n# 14 (2.01e+03,2.07e+03]     7009\n# \n# tem\n#         interval [26.69,26.8] (26.8,27.02] (27.02,27.2]\n# 1   [26.69,26.8]         &lt;NA&gt;         &lt;NA&gt;         &lt;NA&gt;\n# 2   (26.8,27.02]            N         &lt;NA&gt;         &lt;NA&gt;\n# 3   (27.02,27.2]            Y            N         &lt;NA&gt;\n# 4   (27.2,27.33]            Y            N            N\n# 5  (27.33,27.51]            Y            N            N\n# 6  (27.51,27.66]            Y            Y            Y\n# 7  (27.66,27.69]            Y            Y            Y\n# 8  (27.69,27.74]            Y            Y            N\n# 9  (27.74,27.83]            Y            Y            Y\n# 10 (27.83,27.91]            Y            Y            N\n# 11 (27.91,27.96]            N            N            N\n# 12 (27.96,28.02]            Y            Y            N\n# 13 (28.02,28.16]            Y            Y            N\n#    (27.2,27.33] (27.33,27.51] (27.51,27.66] (27.66,27.69]\n# 1          &lt;NA&gt;          &lt;NA&gt;          &lt;NA&gt;          &lt;NA&gt;\n# 2          &lt;NA&gt;          &lt;NA&gt;          &lt;NA&gt;          &lt;NA&gt;\n# 3          &lt;NA&gt;          &lt;NA&gt;          &lt;NA&gt;          &lt;NA&gt;\n# 4          &lt;NA&gt;          &lt;NA&gt;          &lt;NA&gt;          &lt;NA&gt;\n# 5             N          &lt;NA&gt;          &lt;NA&gt;          &lt;NA&gt;\n# 6             Y             Y          &lt;NA&gt;          &lt;NA&gt;\n# 7             Y             Y             N          &lt;NA&gt;\n# 8             N             N             Y             Y\n# 9             Y             Y             N             N\n# 10            N             Y             Y             N\n# 11            N             N             Y             Y\n# 12            Y             Y             N             N\n# 13            N             N             Y             N\n#    (27.69,27.74] (27.74,27.83] (27.83,27.91] (27.91,27.96]\n# 1           &lt;NA&gt;          &lt;NA&gt;          &lt;NA&gt;          &lt;NA&gt;\n# 2           &lt;NA&gt;          &lt;NA&gt;          &lt;NA&gt;          &lt;NA&gt;\n# 3           &lt;NA&gt;          &lt;NA&gt;          &lt;NA&gt;          &lt;NA&gt;\n# 4           &lt;NA&gt;          &lt;NA&gt;          &lt;NA&gt;          &lt;NA&gt;\n# 5           &lt;NA&gt;          &lt;NA&gt;          &lt;NA&gt;          &lt;NA&gt;\n# 6           &lt;NA&gt;          &lt;NA&gt;          &lt;NA&gt;          &lt;NA&gt;\n# 7           &lt;NA&gt;          &lt;NA&gt;          &lt;NA&gt;          &lt;NA&gt;\n# 8           &lt;NA&gt;          &lt;NA&gt;          &lt;NA&gt;          &lt;NA&gt;\n# 9              Y          &lt;NA&gt;          &lt;NA&gt;          &lt;NA&gt;\n# 10             N             Y          &lt;NA&gt;          &lt;NA&gt;\n# 11             N             Y             Y          &lt;NA&gt;\n# 12             N             N             N             Y\n# 13             N             Y             N             N\n#    (27.96,28.02] (28.02,28.16]\n# 1           &lt;NA&gt;          &lt;NA&gt;\n# 2           &lt;NA&gt;          &lt;NA&gt;\n# 3           &lt;NA&gt;          &lt;NA&gt;\n# 4           &lt;NA&gt;          &lt;NA&gt;\n# 5           &lt;NA&gt;          &lt;NA&gt;\n# 6           &lt;NA&gt;          &lt;NA&gt;\n# 7           &lt;NA&gt;          &lt;NA&gt;\n# 8           &lt;NA&gt;          &lt;NA&gt;\n# 9           &lt;NA&gt;          &lt;NA&gt;\n# 10          &lt;NA&gt;          &lt;NA&gt;\n# 11          &lt;NA&gt;          &lt;NA&gt;\n# 12          &lt;NA&gt;          &lt;NA&gt;\n# 13             N          &lt;NA&gt;\n# \n# pre\n#               interval [1.59e+03,1.65e+03] (1.65e+03,1.71e+03]\n# 1  [1.59e+03,1.65e+03]                &lt;NA&gt;                &lt;NA&gt;\n# 2  (1.65e+03,1.71e+03]                   N                &lt;NA&gt;\n# 3  (1.71e+03,1.74e+03]                   N                   N\n# 4  (1.74e+03,1.76e+03]                   N                   N\n# 5  (1.76e+03,1.79e+03]                   Y                   Y\n# 6  (1.79e+03,1.82e+03]                   N                   N\n# 7  (1.82e+03,1.84e+03]                   N                   N\n# 8  (1.84e+03,1.87e+03]                   Y                   Y\n# 9   (1.87e+03,1.9e+03]                   Y                   Y\n# 10  (1.9e+03,1.92e+03]                   Y                   N\n# 11 (1.92e+03,1.95e+03]                   Y                   Y\n# 12 (1.95e+03,1.98e+03]                   Y                   Y\n# 13 (1.98e+03,2.01e+03]                   N                   N\n# 14 (2.01e+03,2.07e+03]                   N                   N\n#    (1.71e+03,1.74e+03] (1.74e+03,1.76e+03] (1.76e+03,1.79e+03]\n# 1                 &lt;NA&gt;                &lt;NA&gt;                &lt;NA&gt;\n# 2                 &lt;NA&gt;                &lt;NA&gt;                &lt;NA&gt;\n# 3                 &lt;NA&gt;                &lt;NA&gt;                &lt;NA&gt;\n# 4                    N                &lt;NA&gt;                &lt;NA&gt;\n# 5                    Y                   Y                &lt;NA&gt;\n# 6                    N                   N                   N\n# 7                    Y                   N                   N\n# 8                    Y                   Y                   N\n# 9                    Y                   Y                   N\n# 10                   Y                   Y                   N\n# 11                   Y                   Y                   N\n# 12                   Y                   Y                   N\n# 13                   Y                   N                   N\n# 14                   Y                   N                   N\n#    (1.79e+03,1.82e+03] (1.82e+03,1.84e+03] (1.84e+03,1.87e+03]\n# 1                 &lt;NA&gt;                &lt;NA&gt;                &lt;NA&gt;\n# 2                 &lt;NA&gt;                &lt;NA&gt;                &lt;NA&gt;\n# 3                 &lt;NA&gt;                &lt;NA&gt;                &lt;NA&gt;\n# 4                 &lt;NA&gt;                &lt;NA&gt;                &lt;NA&gt;\n# 5                 &lt;NA&gt;                &lt;NA&gt;                &lt;NA&gt;\n# 6                 &lt;NA&gt;                &lt;NA&gt;                &lt;NA&gt;\n# 7                    N                &lt;NA&gt;                &lt;NA&gt;\n# 8                    N                   N                &lt;NA&gt;\n# 9                    Y                   N                   N\n# 10                   N                   N                   N\n# 11                   Y                   Y                   N\n# 12                   Y                   Y                   N\n# 13                   N                   N                   N\n# 14                   N                   N                   N\n#    (1.87e+03,1.9e+03] (1.9e+03,1.92e+03] (1.92e+03,1.95e+03]\n# 1                &lt;NA&gt;               &lt;NA&gt;                &lt;NA&gt;\n# 2                &lt;NA&gt;               &lt;NA&gt;                &lt;NA&gt;\n# 3                &lt;NA&gt;               &lt;NA&gt;                &lt;NA&gt;\n# 4                &lt;NA&gt;               &lt;NA&gt;                &lt;NA&gt;\n# 5                &lt;NA&gt;               &lt;NA&gt;                &lt;NA&gt;\n# 6                &lt;NA&gt;               &lt;NA&gt;                &lt;NA&gt;\n# 7                &lt;NA&gt;               &lt;NA&gt;                &lt;NA&gt;\n# 8                &lt;NA&gt;               &lt;NA&gt;                &lt;NA&gt;\n# 9                &lt;NA&gt;               &lt;NA&gt;                &lt;NA&gt;\n# 10                  N               &lt;NA&gt;                &lt;NA&gt;\n# 11                  N                  N                &lt;NA&gt;\n# 12                  N                  N                   N\n# 13                  N                  N                   N\n# 14                  N                  N                   N\n#    (1.95e+03,1.98e+03] (1.98e+03,2.01e+03] (2.01e+03,2.07e+03]\n# 1                 &lt;NA&gt;                &lt;NA&gt;                &lt;NA&gt;\n# 2                 &lt;NA&gt;                &lt;NA&gt;                &lt;NA&gt;\n# 3                 &lt;NA&gt;                &lt;NA&gt;                &lt;NA&gt;\n# 4                 &lt;NA&gt;                &lt;NA&gt;                &lt;NA&gt;\n# 5                 &lt;NA&gt;                &lt;NA&gt;                &lt;NA&gt;\n# 6                 &lt;NA&gt;                &lt;NA&gt;                &lt;NA&gt;\n# 7                 &lt;NA&gt;                &lt;NA&gt;                &lt;NA&gt;\n# 8                 &lt;NA&gt;                &lt;NA&gt;                &lt;NA&gt;\n# 9                 &lt;NA&gt;                &lt;NA&gt;                &lt;NA&gt;\n# 10                &lt;NA&gt;                &lt;NA&gt;                &lt;NA&gt;\n# 11                &lt;NA&gt;                &lt;NA&gt;                &lt;NA&gt;\n# 12                &lt;NA&gt;                &lt;NA&gt;                &lt;NA&gt;\n# 13                   Y                &lt;NA&gt;                &lt;NA&gt;\n# 14                   N                   N                &lt;NA&gt;\n# \n# Interaction detector:\n#   variable   tem pre\n# 1      tem    NA  NA\n# 2      pre 0.321  NA\n# \n# Ecological detector:\n#   variable  tem  pre\n# 1      tem &lt;NA&gt; &lt;NA&gt;\n# 2      pre    Y &lt;NA&gt;",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Spatial analysis for remote sensing data</span>"
    ]
  },
  {
    "objectID": "sec4.html",
    "href": "sec4.html",
    "title": "\n4  Geospatial artificial intelligence (GeoAI) for remote sensing data\n",
    "section": "",
    "text": "4.1 Background and Simple Examples of Machine Learning\nMachine learning (ML) methods have gained popularity in geospatial research due to their ability to model nonlinear relationships from high-dimensional data. One recent development is GPBoost, which integrates tree boosting with Gaussian processes to model both fixed effects and spatial (or other structured) random effects.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Geospatial artificial intelligence (GeoAI) for remote sensing data</span>"
    ]
  },
  {
    "objectID": "sec4.html#geoai-for-spatial-prediction-of-future-bushfire",
    "href": "sec4.html#geoai-for-spatial-prediction-of-future-bushfire",
    "title": "\n4  Geospatial artificial intelligence (GeoAI) for remote sensing data\n",
    "section": "\n4.2 GeoAI for spatial prediction of future bushfire",
    "text": "4.2 GeoAI for spatial prediction of future bushfire\n\n4.2.1 Future climate data collection\n\n\n\n\n\n\nAim\n\n\n\nWe separately collected future climate datasets of temperature and precipitation for the time period 2021–2040 from WorldClim. The previous 2024 data will be used for model training, followed by predicting bushfire burn areas for the time period 2021–2040.\n\n\n\n\n\n\n\n\nDescription of steps\n\n\n\n\nDownload WorldClim future climate datasets of temperature and precipitation for the time period 2021–2040.\nPreprocess the downloaded future climate data and organize it into vector format for subsequent predictions.\n\n\n\nThe data is downloaded from the WorldClim website and stored in the ./data/4. GeoAI Modeling/ directory, with period 2041-2060, GCM：ACCESS-CM2, scenarios:ssp585 (Links:https://www.worldclim.org/data/cmip6/cmip6_clim30s.html) .\n\n4.2.2 GeoAI modelling\n\n\n\n\n\n\nAim\n\n\n\nThe step uses the gpboost model to fit temperature and precipitation data in 2024 for the next step of spatial prediction.\n\n\n\n\n\n\n\n\nDescription of steps\n\n\n\n\nLoad necessary libraries and data.\nBuild the GPBoost model using the data processed in Section 3.\nYou can also explore traditional machine learning models using the caret package.\n\n\n\nExample: Machine learning using caret\n\nCodelibrary(sf)\n\nd24 = read_sf('./data/3. Spatial analysis/burnedarea_2024.shp')\nnames(d24) = c(\"pre\",\"tem\",\"burned\",\"geometry\")\nd24\n# Simple feature collection with 644 features and 3 fields\n# Geometry type: POLYGON\n# Dimension:     XY\n# Bounding box:  xmin: 129 ymin: -14.9 xmax: 131 ymax: -13.3\n# Geodetic CRS:  WGS 84\n# # A tibble: 644 × 4\n#     pre   tem burned                                        geometry\n#   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;                                   &lt;POLYGON [°]&gt;\n# 1  28.0 1893.   1250 ((130 -13.3, 130 -13.3, 130 -13.3, 130 -13.3, …\n# 2  28.0 1856.   1529 ((130 -13.3, 130 -13.3, 130 -13.3, 130 -13.3, …\n# 3  28.0 1888.   2203 ((130 -13.3, 130 -13.3, 130 -13.3, 130 -13.3, …\n# 4  28.0 1884.   1289 ((131 -13.3, 131 -13.3, 131 -13.3, 131 -13.3, …\n# 5  28.0 1865.   4247 ((131 -13.3, 131 -13.3, 131 -13.3, 131 -13.3, …\n# 6  28.0 1873.   1991 ((131 -13.3, 131 -13.3, 131 -13.3, 131 -13.3, …\n# # ℹ 638 more rows\n\nlibrary(caret)\n\n# Prepare non-spatial data\ndf = sf::st_drop_geometry(d24)\n\n# Train linear model with 5-fold CV\nctrl = trainControl(method = \"cv\", number = 5)\n\nmodel_caret = train(\n  burned ~ pre + tem, \n  data = df, \n  method = \"lm\", \n  trControl = ctrl\n)\n\nmodel_caret\n# Linear Regression \n# \n# 644 samples\n#   2 predictor\n# \n# No pre-processing\n# Resampling: Cross-Validated (5 fold) \n# Summary of sample sizes: 516, 516, 514, 515, 515 \n# Resampling results:\n# \n#   RMSE  Rsquared  MAE \n#   4648  0.0657    3922\n# \n# Tuning parameter 'intercept' was held constant at a value of TRUE\n\n\nSee here for more details about the gpboost model on spatio-temporal data.\n\nCodelibrary(sf)\n\nd24 = read_sf('./data/3. Spatial analysis/burnedarea_2024.shp')\nnames(d24) = c(\"pre\",\"tem\",\"burned\",\"geometry\")\nd24\n# Simple feature collection with 644 features and 3 fields\n# Geometry type: POLYGON\n# Dimension:     XY\n# Bounding box:  xmin: 129 ymin: -14.9 xmax: 131 ymax: -13.3\n# Geodetic CRS:  WGS 84\n# # A tibble: 644 × 4\n#     pre   tem burned                                        geometry\n#   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;                                   &lt;POLYGON [°]&gt;\n# 1  28.0 1893.   1250 ((130 -13.3, 130 -13.3, 130 -13.3, 130 -13.3, …\n# 2  28.0 1856.   1529 ((130 -13.3, 130 -13.3, 130 -13.3, 130 -13.3, …\n# 3  28.0 1888.   2203 ((130 -13.3, 130 -13.3, 130 -13.3, 130 -13.3, …\n# 4  28.0 1884.   1289 ((131 -13.3, 131 -13.3, 131 -13.3, 131 -13.3, …\n# 5  28.0 1865.   4247 ((131 -13.3, 131 -13.3, 131 -13.3, 131 -13.3, …\n# 6  28.0 1873.   1991 ((131 -13.3, 131 -13.3, 131 -13.3, 131 -13.3, …\n# # ℹ 638 more rows\n\nlibrary(gpboost)\ngp_model = GPModel(gp_coords = sdsfun::sf_coordinates(d24), \n                   cov_function = \"exponential\")\n# Training\nbst = gpboost(data = as.matrix(sf::st_drop_geometry(d24)[,1:2]), \n              label = as.matrix(sf::st_drop_geometry(d24)[,3,drop = FALSE]), \n              gp_model = gp_model, objective = \"regression_l2\", verbose = 0)\nbst\n# &lt;gpb.Booster&gt;\n#   Public:\n#     add_valid: function (data, name, valid_set_gp = NULL, use_gp_model_for_validation = TRUE) \n#     best_iter: -1\n#     best_score: NA\n#     current_iter: function () \n#     dump_model: function (num_iteration = NULL, feature_importance_type = 0L) \n#     eval: function (data, name, feval = NULL) \n#     eval_train: function (feval = NULL) \n#     eval_valid: function (feval = NULL) \n#     initialize: function (params = list(), train_set = NULL, modelfile = NULL, \n#     lower_bound: function () \n#     params: list\n#     predict: function (data, start_iteration = NULL, num_iteration = NULL, \n#     raw: NA\n#     record_evals: list\n#     reset_parameter: function (params, ...) \n#     rollback_one_iter: function () \n#     save: function () \n#     save_model: function (filename, start_iteration = NULL, num_iteration = NULL, \n#     save_model_to_string: function (start_iteration = NULL, num_iteration = NULL, feature_importance_type = 0L, \n#     set_train_data_name: function (name) \n#     to_predictor: function () \n#     update: function (train_set = NULL, fobj = NULL) \n#     upper_bound: function () \n#   Private:\n#     eval_names: NULL\n#     finalize: function () \n#     fixed_effect_train_loaded_from_file: NULL\n#     get_eval_info: function () \n#     gp_model: GPModel, R6\n#     gp_model_prediction_data_loaded_from_file: FALSE\n#     handle: gpb.Booster.handle\n#     has_gp_model: TRUE\n#     higher_better_inner_eval: NULL\n#     init_predictor: NULL\n#     inner_eval: function (data_name, data_idx, feval = NULL) \n#     inner_predict: function (idx) \n#     is_mean_scale_regression: FALSE\n#     is_predicted_cur_iter: list\n#     label_loaded_from_file: NULL\n#     name_train_set: training\n#     name_valid_sets: list\n#     num_class: 1\n#     num_dataset: 1\n#     predict_buffer: list\n#     residual_loaded_from_file: NULL\n#     set_objective_to_none: FALSE\n#     train_set: gpb.Dataset, R6\n#     train_set_version: 1\n#     use_gp_model_for_validation: TRUE\n#     valid_sets: list\n#     valid_sets_gp: list\n\n\n\n4.2.3 Model validation\n\n\n\n\n\n\nWhy model validation?\n\n\n\nModel validation ensures that your model performs well on unseen data and helps avoid overfitting.\n\n\nCommon validation methods\n\nTrain/test split\nK-fold cross-validation\nLeave-one-out cross-validation (LOOCV)\nCommon evaluation metrics\n\n\nRMSE (Root Mean Squared Error)\n\n\nMAE (Mean Absolute Error)\n\n\nR² (Coefficient of determination)\nExample: Random forest model with RMSE\n\nCodeset.seed(123)\nmodel_rf = train(\n  burned ~ pre + tem, \n  data = df, \n  method = \"rf\", \n  trControl = ctrl,\n  metric = \"RMSE\"\n)\n# note: only 1 unique complexity parameters in default grid. Truncating the grid to 1 .\n\nmodel_rf$results\n#   mtry RMSE Rsquared  MAE RMSESD RsquaredSD MAESD\n# 1    2 4449    0.175 3545    193     0.0224   131\n\n\n\n4.2.4 Spatial prediction\n\n\n\n\n\n\nAim\n\n\n\nIn this step, the gpboost model constructed in the previous step is used to predict the burned area of 2030.\n\n\n\n\n\n\n\n\nDescription of steps\n\n\n\n\nRead the futural climate data.\nProcess the data to use the gpboost model to predict.\nDo spatial prediction by the gpboost model.\n\n\n\n\nCodelibrary(terra)\n\npref = terra::rast('./data/4. GeoAI Modeling/future_prec.tif')\npref\n# class       : SpatRaster \n# size        : 193, 154, 12  (nrow, ncol, nlyr)\n# resolution  : 0.00833, 0.00833  (x, y)\n# extent      : 129, 131, -14.9, -13.3  (xmin, xmax, ymin, ymax)\n# coord. ref. : lon/lat WGS 84 (EPSG:4326) \n# source      : future_prec.tif \n# names       : wc2.1~ec_01, wc2.1~ec_02, wc2.1~ec_03, wc2.1~ec_04, wc2.1~ec_05, wc2.1~ec_06, ...\npref = terra::app(pref,fun = \"sum\",na.rm = TRUE)\nnames(pref) = \"pre\"\npref\n# class       : SpatRaster \n# size        : 193, 154, 1  (nrow, ncol, nlyr)\n# resolution  : 0.00833, 0.00833  (x, y)\n# extent      : 129, 131, -14.9, -13.3  (xmin, xmax, ymin, ymax)\n# coord. ref. : lon/lat WGS 84 (EPSG:4326) \n# source(s)   : memory\n# name        :  pre \n# min value   : 1109 \n# max value   : 1750\n\ntemf = terra::rast('./data/4. GeoAI Modeling/future_tmax.tif')\ntemf\n# class       : SpatRaster \n# size        : 193, 154, 12  (nrow, ncol, nlyr)\n# resolution  : 0.00833, 0.00833  (x, y)\n# extent      : 129, 131, -14.9, -13.3  (xmin, xmax, ymin, ymax)\n# coord. ref. : lon/lat WGS 84 (EPSG:4326) \n# source      : future_tmax.tif \n# names       : wc2.1~ax_01, wc2.1~ax_02, wc2.1~ax_03, wc2.1~ax_04, wc2.1~ax_05, wc2.1~ax_06, ...\ntemf = terra::app(temf,fun = \"mean\",na.rm = TRUE)\nnames(temf) = \"tem\"\ntemf\n# class       : SpatRaster \n# size        : 193, 154, 1  (nrow, ncol, nlyr)\n# resolution  : 0.00833, 0.00833  (x, y)\n# extent      : 129, 131, -14.9, -13.3  (xmin, xmax, ymin, ymax)\n# coord. ref. : lon/lat WGS 84 (EPSG:4326) \n# source(s)   : memory\n# name        :  tem \n# min value   : 33.9 \n# max value   : 37.4\n\nd30 = c(pref,temf)\nd30 = d30 |&gt; \n  terra::as.polygons(aggregate = FALSE) |&gt; \n  sf::st_as_sf() |&gt; \n  dplyr::filter(dplyr::if_all(1:2,\\(.x) !is.na(.x)))\nd30\n# Simple feature collection with 16430 features and 2 fields\n# Geometry type: POLYGON\n# Dimension:     XY\n# Bounding box:  xmin: 129 ymin: -14.9 xmax: 131 ymax: -13.3\n# Geodetic CRS:  WGS 84\n# First 10 features:\n#     pre  tem                       geometry\n# 1  1739 34.6 POLYGON ((130 -13.3, 130 -1...\n# 2  1735 34.6 POLYGON ((130 -13.3, 130 -1...\n# 3  1745 34.6 POLYGON ((130 -13.3, 130 -1...\n# 4  1733 34.6 POLYGON ((130 -13.3, 130 -1...\n# 5  1732 34.6 POLYGON ((130 -13.3, 130 -1...\n# 6  1731 34.7 POLYGON ((130 -13.3, 130 -1...\n# 7  1725 34.8 POLYGON ((130 -13.3, 130 -1...\n# 8  1750 34.8 POLYGON ((130 -13.3, 130 -1...\n# 9  1741 34.8 POLYGON ((130 -13.3, 130 -1...\n# 10 1725 34.7 POLYGON ((130 -13.3, 130 -1...\n\npred = predict(bst, data = as.matrix(sf::st_drop_geometry(d30)[,1:2]), \n               gp_coords_pred = sdsfun::sf_coordinates(d30), \n               predict_var = TRUE, pred_latent = FALSE)\n\nd30$burned = pred$response_mean\nd30\n# Simple feature collection with 16430 features and 3 fields\n# Geometry type: POLYGON\n# Dimension:     XY\n# Bounding box:  xmin: 129 ymin: -14.9 xmax: 131 ymax: -13.3\n# Geodetic CRS:  WGS 84\n# First 10 features:\n#     pre  tem                       geometry burned\n# 1  1739 34.6 POLYGON ((130 -13.3, 130 -1...   3307\n# 2  1735 34.6 POLYGON ((130 -13.3, 130 -1...   3270\n# 3  1745 34.6 POLYGON ((130 -13.3, 130 -1...   3095\n# 4  1733 34.6 POLYGON ((130 -13.3, 130 -1...   3089\n# 5  1732 34.6 POLYGON ((130 -13.3, 130 -1...   3078\n# 6  1731 34.7 POLYGON ((130 -13.3, 130 -1...   3055\n# 7  1725 34.8 POLYGON ((130 -13.3, 130 -1...   3017\n# 8  1750 34.8 POLYGON ((130 -13.3, 130 -1...   2874\n# 9  1741 34.8 POLYGON ((130 -13.3, 130 -1...   2905\n# 10 1725 34.7 POLYGON ((130 -13.3, 130 -1...   2929",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Geospatial artificial intelligence (GeoAI) for remote sensing data</span>"
    ]
  },
  {
    "objectID": "sec1.html#aim",
    "href": "sec1.html#aim",
    "title": "\n1  Remote sensing data collection\n",
    "section": "\n1.3 🎯 Aim",
    "text": "1.3 🎯 Aim\nThis code is designed to compute and export the annual burned area from the MODIS MCD64A1 dataset using Google Earth Engine (GEE).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Remote sensing data collection</span>"
    ]
  },
  {
    "objectID": "sec2.html#temporal-trend-analysis-for-bushfire",
    "href": "sec2.html#temporal-trend-analysis-for-bushfire",
    "title": "\n2  Temporal analysis for remote sensing data\n",
    "section": "",
    "text": "Aim\n\n\n\nThis code is designed to compute the linear trend (slope and intercept) of burned area over time for each grid cell using linear regression, and save the results as a new geotiff.\n\n\n\n\n\n\n\n\nDescription of steps\n\n\n\n\n\nLoad necessary libraries\nLoad required packages for raster processing and file system access:\n\n\nterra for spatial raster operations\n\nfs for file listing and path management\n\n\n\nRead raster files for burned area, precipitation, and temperature\nUse fs::dir_ls() to list .tif files from respective folders and load them into raster stacks with terra::rast().\n\n\nRename raster layers by year (2000–2024)\nAssign meaningful names to each layer using paste0(\"BA\", 2000:2024) (and similarly for Pre and Tem) to standardize temporal reference.\n\n\nResample all raster layers to a common spatial resolution\nEnsure spatial alignment by resampling BA and Pre to match the resolution of Tem:\n\n\nmethod = \"sum\" for burned area aggregation\n\nmethod = \"average\" for precipitation\n\n\n\nCombine all variables into a single raster stack\nMerge burned area, precipitation, and temperature layers into one multi-layer object (grid) for future analyses.\n\n\nDefine the regression function\nCreate a function lm_fun that:\n\nUses year = 2000:2024 as the independent variable\nApplies lm() to fit a linear model of burned area against year\nReturns the intercept, slope (trend), and R² value of the model\n\n\n\nApply the regression model across all raster cells\nUse terra::app() to apply the regression function to each cell of the BA layers (25-year time series), utilizing parallel computing (cores = 8).\n\n\nRename regression result layers\nLabel the output layers as \"intercept\", \"slope\", and \"r2\" to indicate the regression coefficients and model fit.\n\n\n(Optional) Save the regression output or export results\nYou may use terra::writeRaster() to save the ba_lm raster to disk or extract summary statistics for further analysis.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Temporal analysis for remote sensing data</span>"
    ]
  },
  {
    "objectID": "sec3.html#spatial-hotspot-identification",
    "href": "sec3.html#spatial-hotspot-identification",
    "title": "\n3  Spatial analysis for remote sensing data\n",
    "section": "",
    "text": "Aim\n\n\n\nThis step is designed to identify the spatial hot and cold spots of bushfire burned areas, which will be performed using the rgeoda package.\n\n\n\n\n\n\n\n\nDescription of steps\n\n\n\n\nLoad necessary libraries (sf for spatial data, rgeoda for spatial analysis, ggplot2 for data visualization).\nRead the burned area and climate data.\nCreate the spatial weight matrix.\nRun spatial hotspot analysis.\nPlot the result.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Spatial analysis for remote sensing data</span>"
    ]
  },
  {
    "objectID": "sec4.html#analysing-future-bushfire-patterns",
    "href": "sec4.html#analysing-future-bushfire-patterns",
    "title": "\n4  Geospatial artificial intelligence (GeoAI) for remote sensing data\n",
    "section": "\n4.3 Analysing future bushfire patterns",
    "text": "4.3 Analysing future bushfire patterns\n\n\n\n\n\n\nAim\n\n\n\nIn this step, the predicted burned area of 2030 is used to analyse the future bushfire patterns.\n\n\n\n\n\n\n\n\nDescription of steps\n\n\n\n\nVisualise the predicted burned area of 2030.\nAnalyse the future bushfire patterns.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Geospatial artificial intelligence (GeoAI) for remote sensing data</span>"
    ]
  },
  {
    "objectID": "sec4.html#background-and-simple-examples-of-machine-learning",
    "href": "sec4.html#background-and-simple-examples-of-machine-learning",
    "title": "\n4  Geospatial artificial intelligence (GeoAI) for remote sensing data\n",
    "section": "",
    "text": "4.1.1 Example 1: Land Cover Classification from Remote Sensing Imagery\nSatellite images contain multispectral reflectance values across space. GPBoost can be used to classify land cover by combining decision tree boosting (e.g., LightGBM) with a Gaussian Process that accounts for spatial autocorrelation between nearby pixels.\n\n4.1.2 Example 2: Spatial Prediction of Vegetation Index\nNormalized Difference Vegetation Index (NDVI) values derived from remote sensing data often show spatial dependence. GPBoost allows prediction by combining covariates (e.g., elevation, temperature) with spatial random effects.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Geospatial artificial intelligence (GeoAI) for remote sensing data</span>"
    ]
  },
  {
    "objectID": "sec5.html",
    "href": "sec5.html",
    "title": "Practice and Example Datasets",
    "section": "",
    "text": "To facilitate student participation, we provide several example geospatial datasets that can be used directly (including temperature, precipitation, and wildfire burn area data for the corresponding regions in 2024), or participants may use their own data and study areas.\n\nExample Datasets\n\nBlue Mountains, New South Wales (Australia)\nA fire-prone mountainous region just west of Sydney, frequently affected by extreme bushfires such as the 2019–2020 Black Summer fires. Useful for studying peri-urban wildfire risk and climate influence.\ndata file\nAlpine Region, Victoria (Australia)\nLocated in the Victorian Alps northeast of Melbourne, this high-risk bushfire area experiences repeated large-scale wildfires due to dry summers and rugged terrain.\ndata file\nButte County, California (USA) Site of the 2018 Camp Fire, the deadliest wildfire in California history. Suitable for studying extreme wildfire impacts and recovery. data file\nShasta County, California (USA) Known for recurring large wildfires, including the 2018 Carr Fire. Features varied topography and dense vegetation. data file\nBoulder County, Colorado (USA) Located at the plains-mountain interface. High wildfire risk due to dry grasslands, suburban expansion, and strong wind events. data file\n\nParticipants are encouraged to explore these examples or bring their own datasets. GPBoost is especially effective in settings where structured covariates (e.g., reflectance bands, indices) and spatial dependence exist.",
    "crumbs": [
      "Practice and Example Datasets"
    ]
  },
  {
    "objectID": "sec6.html",
    "href": "sec6.html",
    "title": "Brief Introduction to Deep Learning and Transfer Learning",
    "section": "",
    "text": "What is Deep Learning?\nWhile GPBoost is primarily a structured machine learning method, deep learning has shown great promise in handling unstructured remote sensing data, such as imagery or time series.\nDeep learning models, such as Convolutional Neural Networks (CNNs), are commonly applied to:",
    "crumbs": [
      "Brief Introduction to Deep Learning and Transfer Learning"
    ]
  },
  {
    "objectID": "sec6.html#what-is-deep-learning",
    "href": "sec6.html#what-is-deep-learning",
    "title": "Brief Introduction to Deep Learning and Transfer Learning",
    "section": "",
    "text": "Image classification (e.g., identifying land use types)\nObject detection (e.g., buildings, roads)\nSemantic segmentation (e.g., per-pixel classification)",
    "crumbs": [
      "Brief Introduction to Deep Learning and Transfer Learning"
    ]
  },
  {
    "objectID": "sec6.html#what-is-transfer-learning",
    "href": "sec6.html#what-is-transfer-learning",
    "title": "Brief Introduction to Deep Learning and Transfer Learning",
    "section": "What is Transfer Learning?",
    "text": "What is Transfer Learning?\nTransfer learning involves fine-tuning a pre-trained model on a new task, which is useful when labeled data are limited. For instance:\n\nUsing a pre-trained ResNet model to classify crop types from drone imagery after fine-tuning on a small local dataset.",
    "crumbs": [
      "Brief Introduction to Deep Learning and Transfer Learning"
    ]
  },
  {
    "objectID": "sec6.html#complementarity-with-gpboost",
    "href": "sec6.html#complementarity-with-gpboost",
    "title": "Brief Introduction to Deep Learning and Transfer Learning",
    "section": "Complementarity with GPBoost",
    "text": "Complementarity with GPBoost\nIn certain workflows, deep learning can be used for feature extraction (e.g., producing features from images), which are then passed into GPBoost for structured modeling with spatial effects. This hybrid approach leverages both pixel-level detail and geostatistical structure.",
    "crumbs": [
      "Brief Introduction to Deep Learning and Transfer Learning"
    ]
  },
  {
    "objectID": "sec5.html#example-datasets",
    "href": "sec5.html#example-datasets",
    "title": "5  Student Challenge Example Datasets",
    "section": "",
    "text": "Sentinel-2 Land Cover Sample (China)\nA subset of Sentinel-2 imagery with land cover labels across several cities.\nMODIS NDVI Time-Series Data\nMonthly NDVI values from MODIS over East Asia, useful for modeling vegetation trends.\nSurface Temperature and Elevation Data (ASTER GDEM + MODIS LST)\nCombined raster datasets useful for spatial regression or GPBoost modeling.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Student Challenge Example Datasets</span>"
    ]
  }
]