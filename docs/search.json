[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IEEE IGARSS 2025 Summer School",
    "section": "",
    "text": "Preface\nTopic:Tools for remote sensing and geospatial intelligence analysis: An example of climate impact on bushfire.\n\n\n\n\n\n\nNote\n\n\n\nIn each section, we will include Tools, Aim, Description of steps, and Code.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "sec1.html",
    "href": "sec1.html",
    "title": "\n1  Remote sensing data collection\n",
    "section": "",
    "text": "1.1 Define study area\nFigure 1.1: The location of study area, West Daly, in Australia",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Remote sensing data collection</span>"
    ]
  },
  {
    "objectID": "sec1.html#collecting-bushfire-data",
    "href": "sec1.html#collecting-bushfire-data",
    "title": "\n1  Remote sensing data collection\n",
    "section": "\n1.2 Collecting bushfire data",
    "text": "1.2 Collecting bushfire data\n\n\n\n\n\n\nAim\n\n\n\nThis code is designed to compute and export the annual burned area from the MODIS MCD64A1 dataset using Google Earth Engine (GEE).\n\n\n\n\n\n\n\n\nDescription of steps\n\n\n\n\nLoad the MODIS MCD64A1 burned area dataset from GEE.\nDefine a function to clip and export burned area data by year.\nSet a time range (January 1st to December 31st of the given year).\nFilter the dataset for the selected year and extract the burned area information.\nApply an aggregation method (e.g., mean) to summarize burned area data.\nClip the data to the Region of Interest (ROI).\nExport the processed burned area data to Google Drive as a GeoTIFF.\nLoop through the desired years (2023-2024) and execute the function.\n\n\n\n// Load the MODIS MCD64A1 dataset\nvar dataset = ee.ImageCollection(\"MODIS/061/MCD64A1\");\n\n// Define a function to clip the dataset and export it by year\nfunction exportYearlyBurnedArea(year) {\n  // Create a date range for the specific year\n  var startDate = ee.Date.fromYMD(year, 1, 1);\n  var endDate = startDate.advance(1, 'year');\n\n  // Filter the dataset for the specific year and clip to the ROI\n  var yearlyBurnedArea = dataset.filterDate(startDate, endDate)\n                                .select('BurnDate')\n                                .mean()  // Or use another appropriate aggregation method\n                                .clip(roi.geometry().bounds());\n\n  // Export the processed data\n  Export.image.toDrive({\n    image: yearlyBurnedArea,\n    description: 'BurnedArea_' + year,\n    scale: 500,  // Adjust resolution as needed\n    region: roi,\n    fileFormat: 'GeoTIFF'\n  });\n}\n\n// Loop through and export data for the years 2000 to 2023\nfor (var year = 2023; year &lt;= 2024; year++) {\n  exportYearlyBurnedArea(year);\n}\nThe GEE code link: https://code.earthengine.google.com/c4c9731308de7f49c6e468c3daa8cb03 .",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Remote sensing data collection</span>"
    ]
  },
  {
    "objectID": "sec1.html#collecting-climate-data",
    "href": "sec1.html#collecting-climate-data",
    "title": "\n1  Remote sensing data collection\n",
    "section": "\n1.3 Collecting climate data",
    "text": "1.3 Collecting climate data\n\nTemperature\n\n\n\n\n\n\n\nAim\n\n\n\nThis code is designed to compute and export the annual mean temperature from the ERA5-Land Hourly Temperature dataset using GEE.\n\n\n\n\n\n\n\n\nDescription of steps\n\n\n\n\nLoad ERA5 hourly temperature data from Google Earth Engine.\nDefine a function to compute the annual mean temperature.\nSet a time range (January 1st to December 31st of the given year).\nFilter the dataset for the given year and compute the mean temperature.\nConvert temperature from Kelvin to Celsius.\nClip the data to the ROI.\nExport the processed temperature data to Google Drive as a GeoTIFF.\nLoop through the desired years and execute the function.\n\n\n\n// Load the ERA5 daily temperature dataset\nvar dataset = ee.ImageCollection(\"ECMWF/ERA5_LAND/HOURLY\");\n\n// Define a function to calculate and export the annual mean temperature\nfunction exportYearlyTemperature(year) {\n  // Create the date range\n  var startDate = ee.Date.fromYMD(year, 1, 1);\n  var endDate = startDate.advance(1, 'year');\n\n  // Filter the dataset and compute the annual mean temperature (unit: K)\n  var yearlyTemperature = dataset.filterDate(startDate, endDate)\n                                 .select('temperature_2m')\n                                 .mean()  // Compute annual mean temperature\n                                 .subtract(273.15)  // Convert to Celsius\n                                 .clip(roi.geometry().bounds());\n\n  // Export the result to Google Drive\n  Export.image.toDrive({\n    image: yearlyTemperature,\n    description: 'Tem' + year,\n    scale: 5000,  // ERA5 resolution, recommended 5km (5000m)\n    region: roi,\n    fileFormat: 'GeoTIFF'\n  });\n}\n\n// Loop to calculate the annual mean temperature for the years 2000-2024\nfor (var year = 2002; year &lt;= 2002; year++) {\n  exportYearlyTemperature(year);\n}\nThe GEE code link: https://code.earthengine.google.com/5a7f743bb1d0bd174f1d199e26dc4d61 .\n\nPrecipitation\n\n\n\n\n\n\n\nAim\n\n\n\nThis code is designed to compute and export the annual cumulative precipitation from the CHIRPS 5-day interval precipitation dataset using GEE.\n\n\n\n\n\n\n\n\nDescription of steps\n\n\n\n\nLoad CHIRPS 5-day interval precipitation data from Google Earth Engine.\n\nDefine a function to compute the annual cumulative precipitation.\n\nSet a time range (January 1st to December 31st of the given year).\n\nFilter the dataset for the given year and compute the total precipitation.\n\nClip the data** to the ROI.\n\nExport the processed precipitation data to Google Drive as a GeoTIFF.\n\nLoop through the desired years (2000-2024) and execute the function.\n\n\n\n// Load the CHIRPS dataset (5-day interval precipitation)\nvar dataset = ee.ImageCollection(\"UCSB-CHG/CHIRPS/PENTAD\");\n\n// Define a function to calculate and export the annual cumulative precipitation\nfunction exportYearlyPrecipitation(year) {\n  // Create the date range\n  var startDate = ee.Date.fromYMD(year, 1, 1);\n  var endDate = startDate.advance(1, 'year');\n\n  // Filter the dataset and compute the total precipitation for the year\n  var yearlyPrecipitation = dataset.filterDate(startDate, endDate)\n                                   .select('precipitation')\n                                   .sum()  // Compute annual total precipitation\n                                   .clip(roi.geometry().bounds());\n\n  // Export the result to Google Drive\n  Export.image.toDrive({\n    image: yearlyPrecipitation,\n    description: 'Pre' + year,\n    scale: 5000,  // CHIRPS resolution (~5.5 km), adjustable\n    region: roi,\n    fileFormat: 'GeoTIFF'\n  });\n}\n\n// Loop to compute annual cumulative precipitation for the years 2000-2024\nfor (var year = 2000; year &lt;= 2024; year++) {\n  exportYearlyPrecipitation(year);\n}\nThe GEE code link: https://code.earthengine.google.com/e8b09a65c7d506243e0895d7b6af4e41 .",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Remote sensing data collection</span>"
    ]
  },
  {
    "objectID": "sec2.html",
    "href": "sec2.html",
    "title": "2  Temporal analysis for remote sensing data",
    "section": "",
    "text": "2.1 Temporal trend analysis for bushfire\nCode (R version):\nCode (Python version):",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Temporal analysis for remote sensing data</span>"
    ]
  },
  {
    "objectID": "sec2.html#temporal-correlation-analysis-between-bushfire-and-climate",
    "href": "sec2.html#temporal-correlation-analysis-between-bushfire-and-climate",
    "title": "2  Temporal analysis for remote sensing data",
    "section": "2.2 Temporal correlation analysis between bushfire and climate",
    "text": "2.2 Temporal correlation analysis between bushfire and climate\n\n\n\n\n\n\nAim\n\n\n\nThis code is designed to compute the Spearman correlation coefficients and p-values between burned area and precipitation/temperature for each grid cell over the years 2000-2024, and save the results as a new shapefile.\n\n\n\n\n\n\n\n\nDescription of steps\n\n\n\n\nLoad necessary libraries (sf for spatial data and dplyr for data manipulation).\nRead the shapefile containing burned area, precipitation, and temperature data.\nExtract column names corresponding to:\nBurned area (BA_2000 to BA_2024)\nPrecipitation (Pre2000 to Pre2024)\nTemperature (Tem2000 to Tem2024)\nCompute the Spearman correlation for each grid cell:\nBurned area vs. Precipitation (cor_BA_Pre)\nBurned area vs. Temperature (cor_BA_Tem)\nExtract the correlation coefficient (estimate) and p-value (p.value) for statistical significance.\nSave the updated shapefile containing correlation results.\n\n\n\nCode (R version):\n# Load necessary libraries\nlibrary(sf)\nlibrary(dplyr)\n\n# Read the shapefile\ngrid &lt;- st_read(\"/your_path_here/grid5_Sta.shp\")\n\n# Extract column names (ensure column order matches years)\nba_cols &lt;- paste0(\"BA_\", 2000:2024)   # Burned area columns\npre_cols &lt;- paste0(\"Pre\", 2000:2024)  # Precipitation columns\ntem_cols &lt;- paste0(\"Tem\", 2000:2024)  # Temperature columns\n\n# Compute the Spearman correlation and p-values for each grid cell\ngrid &lt;- grid %&gt;%\n  rowwise() %&gt;%\n  mutate(\n    cor_BA_Pre = cor.test(as.numeric(c_across(all_of(ba_cols))), \n                          as.numeric(c_across(all_of(pre_cols))), \n                          method = \"spearman\", use = \"complete.obs\")$estimate,\n    p_BA_Pre = cor.test(as.numeric(c_across(all_of(ba_cols))), \n                        as.numeric(c_across(all_of(pre_cols))), \n                        method = \"spearman\", use = \"complete.obs\")$p.value,\n    \n    cor_BA_Tem = cor.test(as.numeric(c_across(all_of(ba_cols))), \n                          as.numeric(c_across(all_of(tem_cols))), \n                          method = \"spearman\", use = \"complete.obs\")$estimate,\n    p_BA_Tem = cor.test(as.numeric(c_across(all_of(ba_cols))), \n                        as.numeric(c_across(all_of(tem_cols))), \n                        method = \"spearman\", use = \"complete.obs\")$p.value\n  ) %&gt;%\n  ungroup()\n\n# Save the new shapefile\nst_write(grid, \"/your_path_here/grid5_Cor.shp\", delete_layer = TRUE)\nCode (Python version):\nimport geopandas as gpd\nimport numpy as np\nimport pandas as pd\nfrom scipy.stats import pearsonr\n\n# Read the Shapefile\ngdf = gpd.read_file(\"/your_path_here/grid5_Sta_slope.shp\")\n\n# Extract column names for the time series\nyears = list(range(2000, 2025))  # 2000 to 2024\nba_columns = [f\"BA_{year}\" for year in years]\ntem_columns = [f\"Tem{year}\" for year in years]\npre_columns = [f\"Pre{year}\" for year in years]\n\n# Ensure all relevant columns exist in the dataset\nba_columns = [col for col in ba_columns if col in gdf.columns]\ntem_columns = [col for col in tem_columns if col in gdf.columns]\npre_columns = [col for col in pre_columns if col in gdf.columns]\n\n# Check if any required columns are missing\nif not ba_columns or not tem_columns or not pre_columns:\n    raise ValueError(\"BA, Tem, or Pre-related columns are missing. Please check the data file.\")\n\nprint(\"BA Columns:\", ba_columns)\nprint(\"Tem Columns:\", tem_columns)\nprint(\"Pre Columns:\", pre_columns)\n\n# Ensure all data columns are numeric\nfor col in ba_columns + tem_columns + pre_columns:\n    gdf[col] = pd.to_numeric(gdf[col], errors='coerce')\n\n# Function to compute Pearson correlation (excluding zero values)\ndef compute_correlation(row, x_columns):\n    ba_values = row[ba_columns].values.astype(float)\n    x_values = row[x_columns].values.astype(float)\n    \n    # Check if arrays are empty\n    if len(ba_values) == 0 or len(x_values) == 0:\n        return np.nan, np.nan\n    \n    # Filter out NaN and zero values\n    mask = (ba_values != 0) & (x_values != 0) & ~np.isnan(ba_values) & ~np.isnan(x_values)\n    ba_filtered = ba_values[mask]\n    x_filtered = x_values[mask]\n    \n    # Ensure both arrays have at least two valid values\n    if len(ba_filtered) &lt; 2 or len(x_filtered) &lt; 2:\n        return np.nan, np.nan\n    \n    correlation, p_value = pearsonr(ba_filtered, x_filtered)\n    return correlation, p_value\n\n# Compute Pearson correlation and significance level between BA and Tem\ngdf[[\"BA_Tem_corr\", \"BA_Tem_pval\"]] = gdf.apply(lambda row: compute_correlation(row, tem_columns), axis=1, result_type='expand')\n\n# Compute Pearson correlation and significance level between BA and Pre\ngdf[[\"BA_Pre_corr\", \"BA_Pre_pval\"]] = gdf.apply(lambda row: compute_correlation(row, pre_columns), axis=1, result_type='expand')\n\n# Save the results\ngdf.to_file(\"/your_path_here/grid5_Sta_corr.shp\")\n\nprint(\"Pearson correlation analysis between BA and Tem, as well as BA and Pre, has been completed (excluding zero values). Results saved.\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Temporal analysis for remote sensing data</span>"
    ]
  },
  {
    "objectID": "sec3.html",
    "href": "sec3.html",
    "title": "\n3  Spatial analysis for remote sensing data\n",
    "section": "",
    "text": "3.1 Spatial hotspot identification\nWe demonstrate a spatial analysis workflow using the 2024 climate and bushfire data as an example.\nWe will perform spatial hot spot and cold spot analysis using the rgeoda package and conduct spatial stratified heterogeneity analysis using the gdverse package.\nYou can install the required packages using the following commands in the R console:\nNow we read the data to R and perform some basic data exploration：\nSince the row and column numbers of the three rasters are not aligned, we first convert the non-NA cells of the temperature raster into a spatial polygon format. Then, we perform zonal statistics on temperature and wildfire data, and finally, remove all NA values corresponding to the three variables.\nsave the data to a shapefile:\nCodelibrary(sf)\nlibrary(rgeoda)\nlibrary(ggplot2)\n\nburnedarea = read_sf('./data/3. Spatial analysis/burnedarea_2024.shp')\nqueen_w = queen_weights(burnedarea)\nlisa = local_gstar(queen_w,  burnedarea[\"burnedarea\"])\ncats = lisa_clusters(lisa,cutoff = 0.05)\nburnedarea$hcp = factor(lisa_labels(lisa)[cats + 1],level = lisa_labels(lisa))\n\np_color = lisa_colors(lisa)\nnames(p_color) = lisa_labels(lisa)\np_label = lisa_labels(lisa)[sort(unique(cats + 1))]\nggplot(burnedarea) +\n  geom_sf(aes(fill = hcp)) +\n  scale_fill_manual(\n    values = p_color, \n    labels = p_label) +\n  theme_minimal() +\n  labs(fill = \"Cluster Type\")\n\n\n\n\n\n\nFigure 3.3: Bushfire burned area spatial hotspot analysis",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Spatial analysis for remote sensing data</span>"
    ]
  },
  {
    "objectID": "sec3.html#geographical-detector-for-spatial-heterogeneity-and-factor-analysis",
    "href": "sec3.html#geographical-detector-for-spatial-heterogeneity-and-factor-analysis",
    "title": "\n3  Spatial analysis for remote sensing data\n",
    "section": "\n3.2 Geographical detector for spatial heterogeneity and factor analysis",
    "text": "3.2 Geographical detector for spatial heterogeneity and factor analysis\n\n\n\n\n\n\nAim\n\n\n\nThis step is designed to identify the climatic driving factors of bushfire burned area. We will use the gdverse package to analyze the power of determinant of climatic drivers on bushfire burned area based on the optimal parameter geographical detector model.\n\n\n\n\n\n\n\n\nDescription of steps\n\n\n\n\nLoad necessary libraries (sf for spatial data and gdverse for geographical detector analysis).\nRead the burned area and climate data.\nRun the OPGD model.\nPlot the result.\n\n\n\n\nCodelibrary(sf)\nlibrary(gdverse)\n\nburnedarea = read_sf('./data/3. Spatial analysis/burnedarea_2024.shp')\nopgd.m = opgd(burnedarea~tem+pre, data = burnedarea, discnum = 3:15)\nopgd.m\n# ***   Optimal Parameters-based Geographical Detector     \n#                 Factor Detector            \n# \n# | variable | Q-statistic | P-value  |\n# |:--------:|:-----------:|:--------:|\n# |   tem    |   0.1318    | 1.23e-10 |\n# |   pre    |   0.0719    | 8.06e-05 |\nplot(opgd.m)\n\n\n\n\n\n\nFigure 3.4: Climatic driving factors of bushfire burned area",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Spatial analysis for remote sensing data</span>"
    ]
  },
  {
    "objectID": "sec4.html",
    "href": "sec4.html",
    "title": "\n4  Geospatial artificial intelligence (GeoAI) for remote sensing data\n",
    "section": "",
    "text": "4.1 GeoAI for spatial prediction of future bushfire",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Geospatial artificial intelligence (GeoAI) for remote sensing data</span>"
    ]
  },
  {
    "objectID": "sec4.html#geoai-for-spatial-prediction-of-future-bushfire",
    "href": "sec4.html#geoai-for-spatial-prediction-of-future-bushfire",
    "title": "\n4  Geospatial artificial intelligence (GeoAI) for remote sensing data\n",
    "section": "",
    "text": "4.1.1 Future climate data collection\n\n\n\n\n\n\nAim\n\n\n\nWe separately collected CMIP6 datasets of temperature and precipitation for 2024 and 2030. The 2024 data will be used for model training, followed by predicting bushfire burn areas for 2030.\n\n\n\n\n\n\n\n\nDescription of steps\n\n\n\n\nLoad NEX-GDDP-CMIP6 data from Google Earth Engine.\n\nAggregate and export the temperature and precipitation data for 2024.\n\nAggregate and export the temperature and precipitation data for 2030.\n\n\n\n\n// Load the CMIP6 dataset\nvar dataset = ee.ImageCollection(\"NASA/GDDP-CMIP6\")\n  .filter(ee.Filter.eq('model', 'ACCESS-CM2'))  // Select climate model\n  .filter(ee.Filter.eq('scenario', 'ssp585'))  // Select SSP scenario\n  .filterBounds(roi);  // Restrict to the region of interest (ROI)\n\n// Extract variables\nvar temperature = dataset.select('tas');  // Daily mean temperature (unit: K)\nvar precipitation = dataset.select('pr');  // Daily precipitation (unit: kg m-2 s-1)\n\n// Aggregate data for 2024 and 2030\nvar tem24 = temperature.filter(ee.Filter.calendarRange(2024, 2024, 'year')).mean().clip(roi).subtract(273.15);  // Annual mean temperature for 2024 (°C)\nvar tem30 = temperature.filter(ee.Filter.calendarRange(2030, 2030, 'year')).mean().clip(roi).subtract(273.15);  // Annual mean temperature for 2030 (°C)\nvar pre24 = precipitation.filter(ee.Filter.calendarRange(2024, 2024, 'year')).sum().clip(roi).multiply(86400).multiply(365);  // Annual total precipitation for 2024 (mm)\nvar pre30 = precipitation.filter(ee.Filter.calendarRange(2030, 2030, 'year')).sum().clip(roi).multiply(86400).multiply(365);  // Annual total precipitation for 2030 (mm)\n\n// Export aggregated data to Google Drive\nExport.image.toDrive({\n  image: tem24,\n  description: 'tem24',\n  scale: 27830,\n  region: roi,\n  fileFormat: 'GeoTIFF'\n});\nExport.image.toDrive({\n  image: tem30,\n  description: 'tem30',\n  scale: 27830,\n  region: roi,\n  fileFormat: 'GeoTIFF'\n});\nExport.image.toDrive({\n  image: pre24,\n  description: 'pre24',\n  scale: 27830,\n  region: roi,\n  fileFormat: 'GeoTIFF'\n});\nExport.image.toDrive({\n  image: pre30,\n  description: 'pre30',\n  scale: 27830,\n  region: roi,\n  fileFormat: 'GeoTIFF'\n});\n\n4.1.2 GeoAI modelling\n\n\n\n\n\n\nAim\n\n\n\nThe step uses the gpboost model to fit temperature and precipitation data in 2024 for the next step of spatial prediction.\n\n\n\n\n\n\n\n\nDescription of steps\n\n\n\n\nLoad necessary libraries and data.\nRead the data containing burned area and climate data.\nProcess the data to fit the gpboost model.\nBuild an gpboost model.\n\n\n\n\nCodelibrary(terra)\npre24 = terra::rast('./data/4. GeoAI Modeling/pre24.tif')\ntem24 = terra::rast('./data/4. GeoAI Modeling/tem24.tif')\nburnedarea = terra::rast('./data/1. Data collection/BurnedArea/BurnedArea_2024.tif') |&gt; \n  terra::resample(tem24,method = 'average')\nd24 = c(pre24,tem24,burnedarea)\nnames(d24) = c(\"pre\",\"tem\",\"burned\")\nd24 = d24 |&gt; \n  terra::as.polygons(aggregate = FALSE) |&gt; \n  sf::st_as_sf() |&gt; \n  dplyr::filter(dplyr::if_all(1:3,\\(.x) !is.na(.x)))\nd24\n# Simple feature collection with 35 features and 3 fields\n# Geometry type: POLYGON\n# Dimension:     XY\n# Bounding box:  xmin: 129 ymin: -15 xmax: 131 ymax: -13.3\n# Geodetic CRS:  WGS 84\n# First 10 features:\n#       pre  tem burned                       geometry\n# 1  630364 28.7    141 POLYGON ((130 -13.5, 130 -1...\n# 2  644814 28.6    173 POLYGON ((130 -13.5, 130 -1...\n# 3  638137 28.2    178 POLYGON ((131 -13.5, 131 -1...\n# 4  597248 28.7    154 POLYGON ((130 -13.8, 130 -1...\n# 5  606609 28.5    176 POLYGON ((130 -13.8, 130 -1...\n# 6  607450 28.4    182 POLYGON ((130 -13.8, 130 -1...\n# 7  600348 28.3    193 POLYGON ((131 -13.8, 131 -1...\n# 8  568667 28.7    204 POLYGON ((130 -14, 130 -13....\n# 9  580674 28.4    164 POLYGON ((130 -14, 130 -13....\n# 10 575810 28.0    171 POLYGON ((130 -14, 130 -13....\n\nlibrary(gpboost)\ngp_model = GPModel(gp_coords = sdsfun::sf_coordinates(d24), \n                   cov_function = \"exponential\")\n# Training\nbst = gpboost(data = as.matrix(sf::st_drop_geometry(d24)[,1:2]), \n              label = as.matrix(sf::st_drop_geometry(d24)[,3,drop = FALSE]), \n              gp_model = gp_model, objective = \"regression_l2\", verbose = 0)\nbst\n# &lt;gpb.Booster&gt;\n#   Public:\n#     add_valid: function (data, name, valid_set_gp = NULL, use_gp_model_for_validation = TRUE) \n#     best_iter: -1\n#     best_score: NA\n#     current_iter: function () \n#     dump_model: function (num_iteration = NULL, feature_importance_type = 0L) \n#     eval: function (data, name, feval = NULL) \n#     eval_train: function (feval = NULL) \n#     eval_valid: function (feval = NULL) \n#     finalize: function () \n#     initialize: function (params = list(), train_set = NULL, modelfile = NULL, \n#     lower_bound: function () \n#     params: list\n#     predict: function (data, start_iteration = NULL, num_iteration = NULL, \n#     raw: NA\n#     record_evals: list\n#     reset_parameter: function (params, ...) \n#     rollback_one_iter: function () \n#     save: function () \n#     save_model: function (filename, start_iteration = NULL, num_iteration = NULL, \n#     save_model_to_string: function (start_iteration = NULL, num_iteration = NULL, feature_importance_type = 0L, \n#     set_train_data_name: function (name) \n#     to_predictor: function () \n#     update: function (train_set = NULL, fobj = NULL) \n#     upper_bound: function () \n#   Private:\n#     eval_names: NULL\n#     fixed_effect_train_loaded_from_file: NULL\n#     get_eval_info: function () \n#     gp_model: GPModel, R6\n#     gp_model_prediction_data_loaded_from_file: FALSE\n#     handle: gpb.Booster.handle\n#     has_gp_model: TRUE\n#     higher_better_inner_eval: NULL\n#     init_predictor: NULL\n#     inner_eval: function (data_name, data_idx, feval = NULL) \n#     inner_predict: function (idx) \n#     is_predicted_cur_iter: list\n#     label_loaded_from_file: NULL\n#     name_train_set: training\n#     name_valid_sets: list\n#     num_class: 1\n#     num_dataset: 1\n#     predict_buffer: list\n#     residual_loaded_from_file: NULL\n#     set_objective_to_none: FALSE\n#     train_set: gpb.Dataset, R6\n#     train_set_version: 1\n#     use_gp_model_for_validation: TRUE\n#     valid_sets: list\n#     valid_sets_gp: list\n\n\n\n4.1.3 Spatial prediction\n\n\n\n\n\n\nAim\n\n\n\nIn this step, the gpboost model constructed in the previous step is used to predict the burned area of 2030.\n\n\n\n\n\n\n\n\nDescription of steps\n\n\n\n\nRead the 2030 futural climate data.\nProcess the data to use the gpboost model to predict.\nDo spatial prediction by the gpboost model.\n\n\n\n\nCodepre30 = terra::rast('./data/4. GeoAI Modeling/pre30.tif')\ntem30 = terra::rast('./data/4. GeoAI Modeling/tem30.tif')\nd30 = c(pre30,tem30)\nnames(d30) = c(\"pre\",\"tem\")\nd30 = d30 |&gt; \n  terra::as.polygons(aggregate = FALSE) |&gt; \n  sf::st_as_sf() |&gt; \n  dplyr::filter(dplyr::if_all(1:3,\\(.x) !is.na(.x)))\nd30\n# Simple feature collection with 37 features and 2 fields\n# Geometry type: POLYGON\n# Dimension:     XY\n# Bounding box:  xmin: 129 ymin: -15 xmax: 131 ymax: -13.3\n# Geodetic CRS:  WGS 84\n# First 10 features:\n#       pre  tem                       geometry\n# 1  652488 28.6 POLYGON ((130 -13.5, 130 -1...\n# 2  695938 28.6 POLYGON ((130 -13.5, 130 -1...\n# 3  712191 28.4 POLYGON ((130 -13.5, 130 -1...\n# 4  701452 28.1 POLYGON ((131 -13.5, 131 -1...\n# 5  682812 28.5 POLYGON ((130 -13.8, 130 -1...\n# 6  696118 28.4 POLYGON ((130 -13.8, 130 -1...\n# 7  697721 28.3 POLYGON ((130 -13.8, 130 -1...\n# 8  684002 28.2 POLYGON ((131 -13.8, 131 -1...\n# 9  671438 28.5 POLYGON ((130 -14, 130 -13....\n# 10 689152 28.3 POLYGON ((130 -14, 130 -13....\n\npred = predict(bst, data = as.matrix(sf::st_drop_geometry(d30)[,1:2]), \n               gp_coords_pred = sdsfun::sf_coordinates(d30), \n               predict_var = TRUE, pred_latent = FALSE)\n\npred\n# $fixed_effect\n# NULL\n# \n# $random_effect_mean\n# [1] NA\n# \n# $random_effect_cov\n# [1] NA\n# \n# $response_mean\n#  [1] 155 149 172 179 158 171 181 191 193 169 170 174 195 168 180 182\n# [17] 161 153 156 189 176 169 161 141 140 144 158 150 144 125 122 134\n# [33] 129 133 132 129 128\n# \n# $response_var\n#  [1] 320 133 130 135 131 127 127 130 131 127 127 127 130 133 127 127\n# [17] 127 127 130 130 127 127 127 127 130 133 127 127 127 127 130 329\n# [33] 133 130 130 130 135\n\nd30$burned = pred$response_mean\nd30\n# Simple feature collection with 37 features and 3 fields\n# Geometry type: POLYGON\n# Dimension:     XY\n# Bounding box:  xmin: 129 ymin: -15 xmax: 131 ymax: -13.3\n# Geodetic CRS:  WGS 84\n# First 10 features:\n#       pre  tem                       geometry burned\n# 1  652488 28.6 POLYGON ((130 -13.5, 130 -1...    155\n# 2  695938 28.6 POLYGON ((130 -13.5, 130 -1...    149\n# 3  712191 28.4 POLYGON ((130 -13.5, 130 -1...    172\n# 4  701452 28.1 POLYGON ((131 -13.5, 131 -1...    179\n# 5  682812 28.5 POLYGON ((130 -13.8, 130 -1...    158\n# 6  696118 28.4 POLYGON ((130 -13.8, 130 -1...    171\n# 7  697721 28.3 POLYGON ((130 -13.8, 130 -1...    181\n# 8  684002 28.2 POLYGON ((131 -13.8, 131 -1...    191\n# 9  671438 28.5 POLYGON ((130 -14, 130 -13....    193\n# 10 689152 28.3 POLYGON ((130 -14, 130 -13....    169",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Geospatial artificial intelligence (GeoAI) for remote sensing data</span>"
    ]
  },
  {
    "objectID": "sec1.html#aim",
    "href": "sec1.html#aim",
    "title": "\n1  Remote sensing data collection\n",
    "section": "\n1.3 🎯 Aim",
    "text": "1.3 🎯 Aim\nThis code is designed to compute and export the annual burned area from the MODIS MCD64A1 dataset using Google Earth Engine (GEE).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Remote sensing data collection</span>"
    ]
  },
  {
    "objectID": "sec2.html#temporal-trend-analysis-for-bushfire",
    "href": "sec2.html#temporal-trend-analysis-for-bushfire",
    "title": "2  Temporal analysis for remote sensing data",
    "section": "",
    "text": "Aim\n\n\n\nThis code is designed to compute the linear trend (slope and intercept) of burned area over time for each grid cell in a shapefile using linear regression, and save the results as a new shapefile.\n\n\n\n\n\n\n\n\nDescription of steps\n\n\n\n\nLoad necessary libraries (sf for spatial data and dplyr for data manipulation).\nRead the shapefile containing burned area data.\nExtract burned area column names corresponding to years 2000-2024.\nCreate a sequence of years as the independent variable for regression.\nPerform linear regression for each grid cell to estimate slope and intercept:\nUse lm() to fit a linear model with years as the independent variable.\nExtract the slope (trend of burned area change) and intercept.\nRemove the regression model objects to keep only numerical results.\nSave the updated shapefile with computed slope and intercept values.\n\n\n\n\n# Load necessary libraries\nlibrary(sf)\nlibrary(dplyr)\n\n# Read the shapefile\ngrid &lt;- st_read(\"/your_path_here/grid5_Sta.shp\")\n\n# Extract column names (ensure column order matches years)\nba_cols &lt;- paste0(\"BA_\", 2000:2024)  # Burned area for 25 years\n\n# Create a sequence of years (independent variable)\nyears &lt;- 2000:2024\n\n# Compute the regression slope and intercept for each grid cell\ngrid &lt;- grid %&gt;%\n  rowwise() %&gt;%\n  mutate(\n    lm_model = list(lm(as.numeric(c_across(all_of(ba_cols))) ~ years)),  # Linear regression\n    slope = coef(lm_model)[2],   # Slope\n    intercept = coef(lm_model)[1]  # Intercept\n  ) %&gt;%\n  select(-lm_model) %&gt;%  # Remove model object\n  ungroup()\n\n# Save the new shapefile\nst_write(grid, \"/your_path_here/grid5_Linear.shp\", delete_layer = TRUE)\n\nimport geopandas as gpd\nimport numpy as np\nfrom scipy.stats import linregress\n\n# Read the Shapefile\ngdf = gpd.read_file(\"/your_path_here/grid5_Sta.shp\")\n\n# Extract column names for the time series\nyears = list(range(2000, 2025))  # 2000 to 2024\ncolumns = [f\"BA_{year}\" for year in years]\n\n# Ensure all columns exist in the dataset\ncolumns = [col for col in columns if col in gdf.columns]\n\n# Time axis\ntime = np.array(years[:len(columns)])\n\ndef compute_slope(row):\n    y_values = row[columns].values.astype(float)  # Retrieve the time series data for the pixel\n    if np.all(np.isnan(y_values)):  # If all values are NaN, return NaN\n        return np.nan\n    slope, _, _, _, _ = linregress(time, y_values)\n    return slope\n\n# Compute the slope and store it in a new column\ngdf[\"BA_slope\"] = gdf.apply(compute_slope, axis=1)\n\n# Save the results\ngdf.to_file(\"/your_path_here/grid5_Sta_slope.shp\")\n\nprint(\"Linear regression calculation completed, results saved.\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Temporal analysis for remote sensing data</span>"
    ]
  },
  {
    "objectID": "sec3.html#spatial-hotspot-identification",
    "href": "sec3.html#spatial-hotspot-identification",
    "title": "\n3  Spatial analysis for remote sensing data\n",
    "section": "",
    "text": "Aim\n\n\n\nThis step is designed to identify the spatial hot and cold spots of bushfire burned areas, which will be performed using the rgeoda package.\n\n\n\n\n\n\n\n\nDescription of steps\n\n\n\n\nLoad necessary libraries (sf for spatial data, rgeoda for spatial analysis, ggplot2 for data visualization).\nRead the burned area and climate data.\nCreate the spatial weight matrix.\nRun spatial hotspot analysis.\nPlot the result.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Spatial analysis for remote sensing data</span>"
    ]
  },
  {
    "objectID": "sec4.html#analysing-future-bushfire-patterns",
    "href": "sec4.html#analysing-future-bushfire-patterns",
    "title": "\n4  Geospatial artificial intelligence (GeoAI) for remote sensing data\n",
    "section": "\n4.2 Analysing future bushfire patterns",
    "text": "4.2 Analysing future bushfire patterns",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Geospatial artificial intelligence (GeoAI) for remote sensing data</span>"
    ]
  }
]